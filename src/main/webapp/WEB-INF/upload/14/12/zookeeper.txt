zookeeper首先会提供一个集群，客户端发来的请求可能落在任意一个节点
	如果发来的是读请求，那么每个节点都可以进行处理
	如果是写请求，那么如果此节点是follower节点  会将请求转发到leader  
	基于rpc的方式去实现数据提交。所以事务请求到了leader以后，会将此事务发送到集群中的每一个节点（Observer除外），follow节点会返回一个ack给leader节点，leader节点如果发现过半数的节点返回的ack请求是同意，那么就会将事务commit，然后返回信息给客户端
	
	follower
	
	
	2n+1 个节点。zookeeper集群中如果需要正常对外提供服务的话，需要过半数的节点进行投票，
	
	ZAB协议 zookeeper里面用来支持崩溃恢复的原子网络协议，主要用于实现数据一致性
	崩溃恢复：
	1.当leader节点失去了过半的follower节点的联系
	2当leader节点挂掉以后
	集群就会进入崩溃恢复阶段
		对于数据恢复来说：
			已经被处理的消息不能丢失（当leader收到合法数量的ack以后，就会向各个follower广播commit指令，同时自己也会commit这条事务消息，如果follower收到commit命令之前，leader挂掉饿了（部分收到，部分没有收到，）--》）
		1.zab协议需要保证被处理的消息不能丢失
		2.被丢弃的消息不能再次出现
		
	
	
	
	原子广播：
	网络中断或者leader奔溃的时候，
	
	
	消息广播：
	基于2PC的方式来完成事务提交的，当带有事务的消息进入到leader以后，
	1.leader会对每一个消息生成一个zXid(64位的自增id)
	2.把带有zxid消息作为一个提案（）分发给集群中的每一个follow节点，
	3.每个follow节点会把这个提案写入磁盘，然后返回给leader一个ack
	4.leader接受到合法数量的axk以后 再去commit请求
	
	
zookeeper的数据结构：
	基于一种Znode的类文件系统
	节点分为临时节点  顺序节点  持久节点 
	同一个级别的节点不允许有相同的名称
	临时节点下不允许创建子节点
leader的选举机制：
	leader发生选举的情况  第一种就是集群初始化的状态：
		此状态下所有的节点都是looking的状态，由于是初始化的状态，每个节点都会推举自己作为leader，投票所包含的内容（myid，zxid,eposh）,
		然后每个节点都会接受来自于其他服务器的投票，接收到投票以后，首先会验证投票的有效性，
		(1)比如（根据eposh号检查是否是同一次投票）
		(2)eposh号相同的情况下，比较zxid  zxid较大的优先作为leader
		（3）zxid相同的情况下，将比较myid，将myid较大的选举为leader
		对于myid较小的而言，会更新自己原来的投票信息为（myid大，zxid），然后重新投票
		统计投票，对于每一次投票，服务器都会统计投票信息，判断是否已经有过半的机器接受到相同的信息。
		一旦确定了leader，leader就会将自己改变成为leading状态，follower会将自己改变成为following状态
应用场景：
	分布式锁：
		可以利用zookeeper的临时顺序节点来实现分布式锁。由于利用zookeeper的api来实现分布式锁会比较臃肿复杂  curator是对zookeeper的一种封装。使用起来简单方便
	注册中心
	配置中心
	leader选举 kafaka

	